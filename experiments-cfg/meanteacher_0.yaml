experiment: 
  name: mean_teacher
  ema_alpha: 0.98

  consistency_loss_scale: 2
  trade_losses: true
  max_trade: 0.8
  ramp_up: 2000


model: 
  name: Autoencoder
  blocks:
    - 64
    - 128
    - 256
    - 256
  layers_per_block: 2
  bottleneck_dim: 256
  skip_connections: True
  use_skip_convs: False
  residual: True
  
  activation: ReLU
  bn: True
  grayscale: False


augmentation: 
  name: weak2
  strength: 0.6
  proportion: 0.8

optimizer:
  name: Adam
  lr: 0.001
  weight_decay: 0.01

scheduler:
  name: ExponentialLR
  gamma: 0.999
  

batch_size: 256

loss: Kaggle