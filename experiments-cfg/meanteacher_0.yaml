experiment: 
  name: mean_teacher
  ema_alpha: 0.995

  consistency_loss_scale: 1
  trade_losses: false
  max_trade: 0.0
  ramp_up: 3000


model: 
  name: Autoencoder
  blocks:
    - 64
    - 128
    - 256
    - 256
  layers_per_block: 2
  bottleneck_dim: 256
  skip_connections: True
  use_skip_convs: False
  residual: True
  
  activation: ReLU
  bn: True
  grayscale: False


augmentation: 
  name: medium1
  strength: 0.8
  proportion: 0.8

optimizer:
  name: Adam
  lr: 0.002
  weight_decay: 0.01

scheduler:
  name: ExponentialLR
  gamma: 0.997
  

batch_size: 256

loss: Kaggle

early_stopping:
  grace: 80
  min_delta: 10